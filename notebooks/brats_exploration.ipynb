{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a4bacf68",
   "metadata": {},
   "source": [
    "# BraTS Post-treatment Interactive Exploration\n",
    "\n",
    "This notebook provides an end-to-end workspace for inspecting the BraTS 2025 post-treatment dataset, validating geometry and segmentation metadata, and building reusable visualizations/exports for clinical review."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "435eaa37",
   "metadata": {},
   "source": [
    "## 1. Data Loading and Metadata Extraction\n",
    "\n",
    "Load BraTS NIfTI volumes and segmentation masks, collect geometric metadata, and maintain reusable helpers for downstream steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b089aab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import json\n",
    "from dataclasses import dataclass\n",
    "from functools import lru_cache\n",
    "from pathlib import Path\n",
    "from typing import Dict, Iterable, List, Mapping, Tuple\n",
    "\n",
    "import imageio\n",
    "import ipywidgets as widgets\n",
    "import matplotlib.pyplot as plt\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython.display import HTML, clear_output, display\n",
    "from matplotlib.colors import ListedColormap\n",
    "from nibabel.orientations import aff2axcodes\n",
    "\n",
    "# Dataset configuration\n",
    "PROJECT_ROOT = Path(\"..\").resolve()\n",
    "DATA_ROOT = (PROJECT_ROOT / \"training_data_additional\").resolve()\n",
    "MODALITIES = (\"t1c\", \"t1n\", \"t2f\", \"t2w\")\n",
    "LABEL_MAP = {\n",
    "    0: (\"Background\", \"#00000000\"),\n",
    "    1: (\"Enhancing Tumor\", \"#ff4f40\"),\n",
    "    2: (\"Non-Enhancing Tumor\", \"#ffb347\"),\n",
    "    3: (\"Peritumoral Edema\", \"#42c6ff\"),\n",
    "    4: (\"Resection Cavity\", \"#9b59b6\"),\n",
    "}\n",
    "\n",
    "\n",
    "def list_case_dirs(root: Path = DATA_ROOT) -> List[Path]:\n",
    "    return sorted([p for p in root.iterdir() if p.is_dir()])\n",
    "\n",
    "\n",
    "def infer_case_prefix(case_dir: Path) -> str:\n",
    "    return case_dir.name\n",
    "\n",
    "\n",
    "def load_nifti(path: Path) -> nib.Nifti1Image:\n",
    "    if not path.exists():\n",
    "        raise FileNotFoundError(path)\n",
    "    return nib.load(str(path))\n",
    "\n",
    "\n",
    "def get_volume(path: Path) -> np.ndarray:\n",
    "    return load_nifti(path).get_fdata(dtype=np.float32)\n",
    "\n",
    "\n",
    "def get_metadata(case_dir: Path) -> Dict[str, object]:\n",
    "    prefix = infer_case_prefix(case_dir)\n",
    "    t1c_path = case_dir / f\"{prefix}-t1c.nii.gz\"\n",
    "    img = load_nifti(t1c_path)\n",
    "    shape = img.shape\n",
    "    spacing = tuple(float(round(v, 3)) for v in img.header.get_zooms()[:3])\n",
    "    orientation = aff2axcodes(img.affine)\n",
    "    return {\n",
    "        \"case_id\": prefix,\n",
    "        \"shape\": shape,\n",
    "        \"voxel_spacing\": spacing,\n",
    "        \"orientation\": orientation,\n",
    "    }\n",
    "\n",
    "\n",
    "def collect_metadata(root: Path = DATA_ROOT) -> pd.DataFrame:\n",
    "    rows = []\n",
    "    for case_dir in list_case_dirs(root):\n",
    "        try:\n",
    "            rows.append(get_metadata(case_dir))\n",
    "        except FileNotFoundError:\n",
    "            continue\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "\n",
    "metadata_df = collect_metadata()\n",
    "metadata_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "737e434c",
   "metadata": {},
   "source": [
    "## 2. Compute Image Geometry Consistency\n",
    "\n",
    "Summarize dimensions, voxel spacing, and orientation across subjects to detect anomalies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8391526",
   "metadata": {},
   "outputs": [],
   "source": [
    "shape_counts = metadata_df[\"shape\"].value_counts().rename_axis(\"shape\").reset_index(name=\"count\")\n",
    "spacing_counts = metadata_df[\"voxel_spacing\"].value_counts().rename_axis(\"voxel_spacing\").reset_index(name=\"count\")\n",
    "orientation_counts = metadata_df[\"orientation\"].value_counts().rename_axis(\"orientation\").reset_index(name=\"count\")\n",
    "\n",
    "summary = {\n",
    "    \"num_cases\": len(metadata_df),\n",
    "    \"unique_shapes\": shape_counts.shape[0],\n",
    "    \"unique_spacings\": spacing_counts.shape[0],\n",
    "    \"unique_orientations\": orientation_counts.shape[0],\n",
    "}\n",
    "\n",
    "display(pd.DataFrame([summary]))\n",
    "display(shape_counts)\n",
    "display(spacing_counts)\n",
    "display(orientation_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5896e92",
   "metadata": {},
   "source": [
    "## 3. Segmentation Label Analysis\n",
    "\n",
    "Inspect unique label integers, validate tumor sub-region mapping, and compute dataset-wide distributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "425e51e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "\n",
    "def collect_label_statistics(root: Path = DATA_ROOT) -> Tuple[pd.DataFrame, Counter, Dict[int, float]]:\n",
    "    rows = []\n",
    "    aggregate = Counter()\n",
    "    for case_dir in list_case_dirs(root):\n",
    "        prefix = infer_case_prefix(case_dir)\n",
    "        seg_path = case_dir / f\"{prefix}-seg.nii.gz\"\n",
    "        if not seg_path.exists():\n",
    "            continue\n",
    "        data = get_volume(seg_path)\n",
    "        labels, counts = np.unique(np.rint(data).astype(np.int16), return_counts=True)\n",
    "        total_voxels = int(np.prod(data.shape))\n",
    "        record = {\"case_id\": prefix}\n",
    "        case_counter = dict(zip(labels.astype(int), counts.astype(int)))\n",
    "        aggregate.update(case_counter)\n",
    "        for label, (name, _) in LABEL_MAP.items():\n",
    "            voxels = case_counter.get(label, 0)\n",
    "            record[f\"voxels_label_{label}\"] = voxels\n",
    "            record[f\"pct_label_{label}\"] = 100.0 * voxels / total_voxels\n",
    "        rows.append(record)\n",
    "    df = pd.DataFrame(rows)\n",
    "    total = sum(aggregate.values())\n",
    "    aggregate_pct = {label: 100.0 * aggregate.get(label, 0) / total for label in LABEL_MAP}\n",
    "    return df, aggregate, aggregate_pct\n",
    "\n",
    "\n",
    "label_df, label_counts, label_pct = collect_label_statistics()\n",
    "\n",
    "display(pd.DataFrame({\n",
    "    \"label\": list(LABEL_MAP.keys()),\n",
    "    \"region\": [LABEL_MAP[k][0] for k in LABEL_MAP],\n",
    "    \"color\": [LABEL_MAP[k][1] for k in LABEL_MAP],\n",
    "    \"voxel_count\": [label_counts.get(k, 0) for k in LABEL_MAP],\n",
    "    \"dataset_pct\": [round(label_pct.get(k, 0.0), 3) for k in LABEL_MAP],\n",
    "}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bedb8b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f440331",
   "metadata": {},
   "source": [
    "## 4. Multi-Modality Mask Overlay Visualization\n",
    "\n",
    "Render sample slices for each modality with segmentation overlay colors to verify alignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ed8efaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_volume(volume: np.ndarray) -> np.ndarray:\n",
    "    finite = np.isfinite(volume)\n",
    "    if not finite.any():\n",
    "        return np.zeros_like(volume, dtype=np.float32)\n",
    "    cleaned = volume[finite]\n",
    "    lo, hi = np.percentile(cleaned, (1, 99))\n",
    "    if np.isclose(lo, hi):\n",
    "        lo, hi = float(cleaned.min()), float(cleaned.max())\n",
    "    if np.isclose(lo, hi):\n",
    "        return np.clip(volume, 0.0, 1.0)\n",
    "    normed = (volume - lo) / (hi - lo)\n",
    "    return np.clip(normed, 0.0, 1.0)\n",
    "\n",
    "\n",
    "def prepare_slice(volume: np.ndarray, axis: int, index: int) -> np.ndarray:\n",
    "    slicer = [slice(None)] * 3\n",
    "    slicer[axis] = index\n",
    "    data = volume[tuple(slicer)]\n",
    "    if axis == 2:  # axial\n",
    "        return np.rot90(data)\n",
    "    if axis == 1:  # coronal\n",
    "        return np.rot90(np.flipud(data))\n",
    "    return np.rot90(np.flipud(data))  # sagittal\n",
    "\n",
    "\n",
    "def build_segmentation_colormap() -> ListedColormap:\n",
    "    rgba = [plt.matplotlib.colors.to_rgba(LABEL_MAP[label][1]) for label in sorted(LABEL_MAP)]\n",
    "    return ListedColormap(rgba)\n",
    "\n",
    "\n",
    "def load_case_volumes(case_id: str, root: Path = DATA_ROOT) -> Dict[str, np.ndarray]:\n",
    "    case_dir = root / case_id\n",
    "    volumes = {}\n",
    "    for modality in MODALITIES:\n",
    "        path = case_dir / f\"{case_id}-{modality}.nii.gz\"\n",
    "        if path.exists():\n",
    "            volumes[modality] = normalize_volume(get_volume(path))\n",
    "    if not volumes:\n",
    "        raise FileNotFoundError(f\"No modalities found for {case_id}\")\n",
    "    return volumes\n",
    "\n",
    "\n",
    "def load_segmentation(case_id: str, root: Path = DATA_ROOT) -> np.ndarray:\n",
    "    seg_path = root / case_id / f\"{case_id}-seg.nii.gz\"\n",
    "    if not seg_path.exists():\n",
    "        raise FileNotFoundError(f\"No segmentation for {case_id}\")\n",
    "    return np.rint(get_volume(seg_path)).astype(np.int16)\n",
    "\n",
    "\n",
    "def plot_modalities_with_overlay(case_id: str, axis: str = \"axial\", fraction: float = 0.5) -> None:\n",
    "    axis_map = {\"sagittal\": 0, \"coronal\": 1, \"axial\": 2}\n",
    "    axis_idx = axis_map[axis]\n",
    "    volumes = load_case_volumes(case_id)\n",
    "    segmentation = load_segmentation(case_id)\n",
    "    size = volumes[MODALITIES[0]].shape[axis_idx]\n",
    "    slice_idx = int(np.clip(round(fraction * (size - 1)), 0, size - 1))\n",
    "\n",
    "    cmap = build_segmentation_colormap()\n",
    "    fig, axes = plt.subplots(1, len(volumes), figsize=(4.2 * len(volumes), 4))\n",
    "    if len(volumes) == 1:\n",
    "        axes = [axes]\n",
    "\n",
    "    for ax, (modality, volume) in zip(axes, volumes.items()):\n",
    "        img_slice = prepare_slice(volume, axis_idx, slice_idx)\n",
    "        ax.imshow(img_slice, cmap=\"gray\", interpolation=\"none\")\n",
    "        seg_slice = prepare_slice(segmentation, axis_idx, slice_idx)\n",
    "        mask = np.ma.masked_where(seg_slice < 0.5, seg_slice)\n",
    "        ax.imshow(mask, cmap=cmap, alpha=0.45, interpolation=\"none\")\n",
    "        ax.set_title(f\"{modality.upper()} — {axis} slice {slice_idx}\")\n",
    "        ax.axis(\"off\")\n",
    "\n",
    "    handles = [plt.matplotlib.patches.Patch(color=LABEL_MAP[label][1], label=f\"{label}: {LABEL_MAP[label][0]}\")\n",
    "               for label in sorted(LABEL_MAP) if label != 0]\n",
    "    fig.legend(handles=handles, loc=\"lower center\", ncol=min(4, len(handles)))\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "plot_modalities_with_overlay(metadata_df.case_id.iloc[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84091483",
   "metadata": {},
   "source": [
    "## 5. Interactive Volume Inspection Widgets\n",
    "\n",
    "Use `ipywidgets` to browse modalities, planes, and slices with segmentation overlays in real time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2668302b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def render_single_slice(case_id: str, modality: str, axis: str, index: int, overlay: bool = True) -> None:\n",
    "    axis_map = {\"sagittal\": 0, \"coronal\": 1, \"axial\": 2}\n",
    "    volumes = load_case_volumes(case_id)\n",
    "    volume = volumes[modality]\n",
    "    segmentation = load_segmentation(case_id)\n",
    "    axis_idx = axis_map[axis]\n",
    "    img_slice = prepare_slice(volume, axis_idx, index)\n",
    "    fig, ax = plt.subplots(figsize=(5, 5))\n",
    "    ax.imshow(img_slice, cmap=\"gray\", interpolation=\"none\")\n",
    "    if overlay:\n",
    "        seg_slice = prepare_slice(segmentation, axis_idx, index)\n",
    "        cmap = build_segmentation_colormap()\n",
    "        mask = np.ma.masked_where(seg_slice < 0.5, seg_slice)\n",
    "        ax.imshow(mask, cmap=cmap, alpha=0.45, interpolation=\"none\")\n",
    "    ax.set_title(f\"{case_id} — {modality.upper()} — {axis} slice {index}\")\n",
    "    ax.axis(\"off\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def launch_interactive_viewer() -> widgets.VBox:\n",
    "    if metadata_df.empty:\n",
    "        raise RuntimeError(\"No cases loaded. Check DATA_ROOT path.\")\n",
    "\n",
    "    case_options = metadata_df.case_id.tolist()\n",
    "    axis_options = [\"sagittal\", \"coronal\", \"axial\"]\n",
    "\n",
    "    case_select = widgets.Dropdown(options=case_options, value=case_options[0], description=\"Case\")\n",
    "    modality_select = widgets.Dropdown(options=MODALITIES, value=\"t1c\", description=\"Modality\")\n",
    "    axis_select = widgets.Dropdown(options=axis_options, value=\"axial\", description=\"Axis\")\n",
    "    overlay_toggle = widgets.Checkbox(value=True, description=\"Overlay mask\")\n",
    "    slice_slider = widgets.IntSlider(value=0, min=0, max=1, step=1, description=\"Slice\")\n",
    "    output = widgets.Output()\n",
    "\n",
    "    axis_map = {\"sagittal\": 0, \"coronal\": 1, \"axial\": 2}\n",
    "\n",
    "    def update_slider(*_):\n",
    "        volumes = load_case_volumes(case_select.value)\n",
    "        axis_idx = axis_map[axis_select.value]\n",
    "        size = volumes[modality_select.value].shape[axis_idx]\n",
    "        slice_slider.max = max(size - 1, 0)\n",
    "        if slice_slider.value > slice_slider.max:\n",
    "            slice_slider.value = slice_slider.max // 2 if slice_slider.max > 0 else 0\n",
    "\n",
    "    def render(*_):\n",
    "        with output:\n",
    "            clear_output(wait=True)\n",
    "            render_single_slice(\n",
    "                case_id=case_select.value,\n",
    "                modality=modality_select.value,\n",
    "                axis=axis_select.value,\n",
    "                index=slice_slider.value,\n",
    "                overlay=overlay_toggle.value,\n",
    "            )\n",
    "\n",
    "    # Wire events\n",
    "    case_select.observe(lambda change: (update_slider(), render()), names=\"value\")\n",
    "    modality_select.observe(lambda change: (update_slider(), render()), names=\"value\")\n",
    "    axis_select.observe(lambda change: (update_slider(), render()), names=\"value\")\n",
    "    slice_slider.observe(lambda change: render(), names=\"value\")\n",
    "    overlay_toggle.observe(lambda change: render(), names=\"value\")\n",
    "\n",
    "    update_slider()\n",
    "    render()\n",
    "\n",
    "    controls = widgets.HBox([case_select, modality_select, axis_select, overlay_toggle])\n",
    "    layout = widgets.VBox([controls, slice_slider, output])\n",
    "    display(layout)\n",
    "    return layout\n",
    "\n",
    "\n",
    "launch_interactive_viewer();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eef1bd0",
   "metadata": {},
   "source": [
    "## 6. Per-Case Histogram Statistics\n",
    "\n",
    "Generate intensity histograms per modality and label-volume summaries to quantify patient-level variation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8e398fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_case_histograms(case_id: str) -> None:\n",
    "    volumes = load_case_volumes(case_id)\n",
    "    segmentation = load_segmentation(case_id)\n",
    "\n",
    "    fig, axes = plt.subplots(1, len(MODALITIES), figsize=(5 * len(MODALITIES), 4))\n",
    "    for ax, modality in zip(axes, MODALITIES):\n",
    "        data = volumes[modality]\n",
    "        ax.hist(data.flatten(), bins=100, range=(0.0, 1.0), color=\"steelblue\")\n",
    "        ax.set_title(f\"{modality.upper()} intensity\")\n",
    "        ax.set_xlabel(\"Normalized intensity\")\n",
    "        ax.set_ylabel(\"Voxel count\")\n",
    "        ax.grid(True, alpha=0.2)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    label_counts_case = [int((segmentation == label).sum()) for label in LABEL_MAP]\n",
    "    fig, ax = plt.subplots(figsize=(6, 4))\n",
    "    bars = ax.bar([str(label) for label in LABEL_MAP], label_counts_case, color=[LABEL_MAP[label][1] for label in LABEL_MAP])\n",
    "    ax.set_title(f\"Segmentation volumes — {case_id}\")\n",
    "    ax.set_xlabel(\"Label\")\n",
    "    ax.set_ylabel(\"Voxel count\")\n",
    "    for rect, count in zip(bars, label_counts_case):\n",
    "        ax.text(rect.get_x() + rect.get_width() / 2, rect.get_height(), f\"{count:,}\", ha=\"center\", va=\"bottom\", fontsize=8)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "plot_case_histograms(metadata_df.case_id.iloc[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d36c8029",
   "metadata": {},
   "source": [
    "## 7. Batch GIF Generation Pipeline\n",
    "\n",
    "Convert volume slices to animations for quality review, exporting per-case GIFs with optional segmentation overlays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1f8db4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def render_gif_frame(volume: np.ndarray, segmentation: np.ndarray | None, axis_idx: int, index: int, overlay: bool) -> np.ndarray:\n",
    "    fig, ax = plt.subplots(figsize=(4, 4))\n",
    "    ax.imshow(prepare_slice(volume, axis_idx, index), cmap=\"gray\", interpolation=\"none\")\n",
    "    if overlay and segmentation is not None:\n",
    "        seg_slice = prepare_slice(segmentation, axis_idx, index)\n",
    "        mask = np.ma.masked_where(seg_slice < 0.5, seg_slice)\n",
    "        cmap = build_segmentation_colormap()\n",
    "        ax.imshow(mask, cmap=cmap, alpha=0.45, interpolation=\"none\")\n",
    "    ax.axis(\"off\")\n",
    "    fig.canvas.draw()\n",
    "    frame = np.frombuffer(fig.canvas.tostring_rgb(), dtype=np.uint8)\n",
    "    frame = frame.reshape(fig.canvas.get_width_height()[::-1] + (3,))\n",
    "    plt.close(fig)\n",
    "    return frame\n",
    "\n",
    "\n",
    "def create_case_gif(\n",
    "    case_id: str,\n",
    "    modality: str = \"t1c\",\n",
    "    axis: str = \"axial\",\n",
    "    overlay: bool = True,\n",
    "    step: int = 2,\n",
    "    output_dir: Path = PROJECT_ROOT / \"outputs\" / \"gifs\",\n",
    "    fps: int = 15,\n",
    ") -> Path:\n",
    "    axis_map = {\"sagittal\": 0, \"coronal\": 1, \"axial\": 2}\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    volumes = load_case_volumes(case_id)\n",
    "    segmentation = load_segmentation(case_id) if overlay else None\n",
    "    volume = volumes[modality]\n",
    "    axis_idx = axis_map[axis]\n",
    "\n",
    "    frames = []\n",
    "    for idx in range(0, volume.shape[axis_idx], step):\n",
    "        frames.append(render_gif_frame(volume, segmentation, axis_idx, idx, overlay))\n",
    "\n",
    "    gif_path = output_dir / f\"{case_id}_{modality}_{axis}.gif\"\n",
    "    imageio.mimsave(gif_path, frames, fps=fps)\n",
    "    print(f\"Saved GIF -> {gif_path}\")\n",
    "    return gif_path\n",
    "\n",
    "\n",
    "# Example (commented to avoid long runs by default)\n",
    "# create_case_gif(metadata_df.case_id.iloc[0], modality=\"t2f\", axis=\"axial\", overlay=True, step=3)\n",
    "\n",
    "print(\"GIF pipeline ready — uncomment the example above to generate outputs.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
